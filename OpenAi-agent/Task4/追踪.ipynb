{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22ece6d1",
   "metadata": {},
   "source": [
    "# 追踪功能`Tracing`\n",
    "强大的工具，辅助深入理解、调试和监控Agent的运行过程\n",
    "\n",
    "## Motivation\n",
    "为什么日志`logging`还不够，还得用追踪？\n",
    "- 日志为离散数据，记录时间点与事件\n",
    "多路由、步骤、Agent、工具的Workflow需要理解：\n",
    "- 整个流程的全貌：input to output，整个过程经历了什么阶段\n",
    "- 事件之间的关联性：“Agent调用Tools”，“该工具调用是哪个父任务的一部分”\n",
    "- 时间关系和性能的瓶颈：“某个步骤耗时过长”，“哪些步骤是并行执行的”\n",
    "\n",
    "`Tracing`就是为了解决这些问题而设计，不仅仅记录单个时间，而是记录事件之间的关系和时间跨度。\n",
    "将一次完整的端到端操作（比如用户问一个问题，Agent调用工具，最终给出答案）表示为一个Trace (追踪记录)，并将这个Trace分解为多个Span (跨度)，每个Span代表其中的一个操作单元（比如一次LLM调用、一次工具调用）。\n",
    "\n",
    "通过追踪可以进行整个完整事件执行的子事件切片，进行诊断、理解、观察、优化\n",
    "\n",
    "## Definition\n",
    "### Trace（追踪记录）\n",
    "代表一个完整的工作流或请求的端到端记录。由一系列的Span组成。\n",
    "核心属性：\n",
    "- `trace_id`：唯一标识，用于追踪整个请求的生命周期\n",
    "- `workflow_name`：工作流名称（如“翻译任务”）\n",
    "- `group_id`(可选)：用于将多次相关的Trace关联起来（如同相关的工作流事件的关联对话）\n",
    "- `metadata`（可选）：可以附加一些自定义的元数据，比如用户ID、任务类型、请求来源等\n",
    "\n",
    "### Span（跨度）\n",
    "代表Trace中的一个具体的操作单元，有明确的开始和结束时间。\n",
    "Span可以嵌套，形成父子关系。\n",
    "- `start_time`：记录Span开始的时间\n",
    "- `end_time`：记录Span结束的时间\n",
    "- `trace_id`：它所归属的Trace的ID\n",
    "- `span_id`：唯一标识，用于追踪单个操作单元\n",
    "- `parent_span_id`/`parent_id`：可选，用于表示当前Span的父Span，形成Span树结构\n",
    "- `span_data`:包含该操作的具体细节，SDK根据操作类型提供了不同的`SpanData`子类，如：\n",
    "    - `AgentSpanData`:记录哪个Agent运行了，以及它的配置参数\n",
    "    - `GenerationSpanData`:记录LLM调用的输入、输出、模型名称等\n",
    "    - `FunctionSpanData`:记录工具（函数）调用的输入、输出\n",
    "    - `GuardrailSpanData`,`HandoffSpanData`,`TranscriptionSpanData`等\n",
    "\n",
    "## Design & Implementation\n",
    "`openai-agent`SDK中的追踪\n",
    "### 默认追踪行为\n",
    "`openai-agent`SDK默认开启追踪功能，所有的操作都会创建Trace和Span：\n",
    "- 每次调用`Runner.run()`、`run_sync()`、`run_streamed()`等运行方法时，都会自动创建一个根Trace（默认名为`Agent trace`）\n",
    "- 拆解此`Trace`内部：\n",
    "    - 每个Agent的运行都会被包裹在`agent_span()`中\n",
    "    - 每次LLM调用会被包裹在`llm_span()`中\n",
    "    - 每次函数工具调用会被包裹在`function_span()`中\n",
    "    - 护栏触发（`guardrail_span()`）、任务交接（`handoff_span()`）、语言处理（`transcription_span()`）、`speech_span()`等操作也会被包裹在对应的Span中\n",
    "\n",
    "这意味着不需要手动添加追踪代码\n",
    "\n",
    ">此处的SDK指的是什么？\n",
    "\n",
    "### 禁用追踪\n",
    "如果你不需要追踪功能（比如性能要求极其高的生产环境中，或者只是想让输出更干净），可以通过一以下都是禁用：\n",
    "- 环境变量（全局禁用）：`export OPENAI_AGENTS_DISABLE_TRACING=1`\n",
    "- 代码中设置（局部禁用，如单个文件）：设置`set_tracing_disabled(disable=True)`\n",
    "- RunConfig(单次运行禁用)：`Runner.run(...,run_config=RunConfig(tracing_disabled=True))`\n",
    "\n",
    "### 高阶追踪：将多次运行合并到一个Trace\n",
    "默认情况下，每次`Runner.run()`调用会创建一个新的Trace。\n",
    "但是需要进行逻辑上相关的多次运行（比如一个多步骤工作流中的不同阶段）归属到同一个Trace下，一边查看完整端到端的执行过程。\n",
    "\n",
    "示例`trace()`上下文管理器：\n",
    "```python\n",
    "from agents import Agent, Runner, trace\n",
    "import asyncio\n",
    "# ... (LLM配置, Agent定义等) ...\n",
    "\n",
    "async def main():\n",
    "    agent = Agent(name=\"Joke generator\", instructions=\"Tell funny jokes.\")\n",
    "\n",
    "    # 使用 trace() 将两次 Runner.run 调用包裹起来\n",
    "    with trace(\"Joke workflow\"): # \"Joke workflow\" 是这次合并追踪的名称\n",
    "        # 第一次运行：让Agent讲个笑话\n",
    "        first_result = await Runner.run(agent, \"Tell me a joke\")\n",
    "        \n",
    "        # 第二次运行：让Agent评价上一个笑话\n",
    "        # 这次运行产生的Spans会自动成为 \"Joke workflow\" Trace 的一部分\n",
    "        second_result = await Runner.run(agent, f\"Rate this joke: {first_result.final_output}\")\n",
    "        \n",
    "        print(f\"Joke: {first_result.final_output}\")\n",
    "        print(f\"Rating: {second_result.final_output}\")\n",
    "\n",
    "# ... (运行代码) ...\n",
    "```\n",
    "\n",
    "### 自动化追踪处理器（`set_trace_processors()`）\n",
    "SDK默认的追踪处理器可能只是将追踪数据打印到控制台或存储在内存中。如果你想将这些宝贵的追踪数据发送到专门的可视化平台（如 LangSmith 或 Langfuse）进行分析和长期存储，就需要替换默认的处理器。\n",
    "\n",
    ">重新实操一遍\n",
    "1. LangSmith集成\n",
    "- 安装依赖：`pip install langsmith`\n",
    "- 配置环境变量：`export LANGSMITH_API_KEY=your_api_key`\n",
    "- 设置追踪处理器：`set_trace_processors([LangSmithTraceProcessor()])`\n",
    "```python\n",
    "import asyncio\n",
    "from agents import Agent, Runner, set_trace_processors\n",
    "from langsmith.wrappers import OpenAIAgentsTracingProcessor\n",
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "# 从环境变量中读取api_key\n",
    "api_key = os.getenv('mistral_key')\n",
    "base_url = 'https://api.mistral.ai/v1'\n",
    "chat_model = \"mistral/mistral-small-latest\"\n",
    "llm = LitellmModel(model=chat_model, api_key=api_key, base_url=base_url)\n",
    "\n",
    "async def main():\n",
    "    agent = Agent(\n",
    "        name=\"Captain Obvious\",\n",
    "        instructions=\"You are Captain Obvious, the world's most literal technical support agent.\",\n",
    "        model=llm,\n",
    "    )\n",
    "\n",
    "    question = \"Why is my code failing when I try to divide by zero? I keep getting this error message.\"\n",
    "    result = await Runner.run(agent, question)\n",
    "    print(result.final_output)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    set_trace_processors([OpenAIAgentsTracingProcessor()])\n",
    "    asyncio.run(main())\n",
    "```\n",
    "\n",
    "2. Langfuse集成\n",
    "```python\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
