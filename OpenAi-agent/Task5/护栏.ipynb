{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4155e2a9",
   "metadata": {},
   "source": [
    "# 护栏（Guardrails）\n",
    "## Motivation\n",
    "核心目的是防止Agent被：\n",
    "- 恶意使用\n",
    "- 成本控制：用户的问题超出了Agent的服务范围，直接让昂贵的模型去处理也是一种浪费\n",
    "- 策略执行：Agent的回答符合公司的规定，比如不涉及某些敏感话题，或者必须包含特定的免责声明\n",
    "\n",
    "护栏机制是为了在Agent处理输入或生成输出的前后，对其内容进行检查、验证甚至修改\n",
    "\n",
    "Guardrails通常与主Agent并行运行（或者更准确地说，是在主Agent运行之前或之后运行，但使用独立的、可能更快速廉价的模型）。\n",
    "如果Guardrails检测到问题会第一时间触发警报tripwire，阻止主Agent继续运行。\n",
    "\n",
    "## Definition\n",
    "`openai-agents`框架定义两种类型护栏：\n",
    "1. 输出护栏（Input guardrails）：\n",
    "    - 在主要Agent开始处理用户输入之前运行\n",
    "    - 检查用户原始请求是否合规、是否在服务范围内、是否包含敏感词等\n",
    "    - 触发时机：在工作流的第一个Agent接收到初始用户输入时运行。*（原因：护栏通常与特定的Agent及其职责相关，将其配置在Agent上更清晰；但输入验证通常只针对外部用户的初始输入，而非Agent之间的内部消息）*。\n",
    "2. 输出护栏（Output guardrails）：\n",
    "    - 在主Agent生成最终输出之后，返回给用户之前运行。\n",
    "    - 检查Agent的输出是否符合公司的规定，比如不涉及敏感话题、包含特定免责声明等\n",
    "    - 触发时机：在工作流的最后一个Agent生成输出后运行。\n",
    "\n",
    "拆解Guardrails：\n",
    "- 护栏函数（Guardrail functions）：\n",
    "    - 定义了具体的检查逻辑，比如是否包含敏感词、是否在服务范围内等\n",
    "    - 可以是同步函数，也可以是异步函数，根据需要选择\n",
    "    - 可以在Agent运行前或后调用，根据触发时机选择"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a34948",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
