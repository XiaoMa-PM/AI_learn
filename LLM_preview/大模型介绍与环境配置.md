---

---
# 大模型介绍与环境配置
---
RTX4090 16G以上
本章任务：
1. 建立对大模型的基本认知
2. 将来做实验用的计算机环境配置好
## 一、什么是大模型
---
### 1. 大模型的基本概念
#### 1.1 NLP的传统任务有哪些？
参照：[1. 学习NLP的应用](../Happy_LLM/前言&回顾.md#1.%20学习NLP的应用)

#### 1.2 什么是大模型
LLM
- 参数规模大（参数规模可以理解为BP，BP越多，记住和学习的知识就越多）
- 训练数量大 
大模型属于通用的、与训练过的语言模型。其训练目的为预测下一个词（Token）是什么？
通过Encoder和Decoder一并让模型学会了语法、事实知识、逻辑推理等。

## 二、大模型与传统NLP模型（Bert）有什么不同？
---

| 特性         | 传统NLP模型（以BERT为例）                          | 大语言模型（以Qwen3系列为例）                            |
| :----------- | :------------------------------------------------- | :------------------------------------------------------- |
| 模型规模     | 亿级参数（e.g., BERT-base: 1.1亿）                 | 十亿到万亿级参数（e.g., Qwen3-235B-A22B: 2350亿）       |
| 核心思想     | 专业模式：针对特定任务进行微调（Fine-tuning）      | 通用模式：通过提示（Prompting）来解决各种任务           |
| 使用方式     | 需要在特定任务的数据集上进一步训练模型             | 基本不需要额外训练，直接通过给指令的方式使用            |
| 任务灵活性   | 一个模型主要服务一个或少数几个任务                 | 一个模型可以完成开放、多样的任务（对话、写作、翻译、写代码等） |
## 三、服务器环境配置
---
### 3.1 环境配置

### 3.2 配置大模型下载和运行环境
Hugging Face全球最大的机器学习模型开源社区，提供了大量预训练、数据和工具
ModelScrope是阿里云推出的模型开源社区平台


## 四、模型下载
---