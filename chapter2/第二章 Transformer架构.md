# 第二章 Transformer架构
---

## 一、注意力机制
---

### 1. 什么是注意力机制

### 2. 深入理解注意力机制

### 3. 注意力机制的实现

### 4. 自注意力

### 5. 掩码自注意力

### 6. 多头注意力

## 二、Encoder-Decoder
---
### 1. Seq2Seq模型

### 2. 前馈神经网络

### 3. 层归一化

### 4. 残差连接

### 5. Encoder

### 6. Decoder

## 三、搭建一个Transformer
---

### 1. Embedding层

### 2. 位置编码

### 3. 一个完整的Transformer