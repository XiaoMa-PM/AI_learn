# 一、NLP 发展脉络与 LLM 的突破性

## 1. NLP技术演进
从符号主义、统计学习到深度学习阶段，最终进入 ​**预训练语言模型（PLM）​**​ 时代（如 BERT、GPT）。PLM 基于 Transformer 架构，通过预训练-微调范式提升语言理解能力，但仍依赖监督数据

## 2. LLM质变
LLM 在 PLM 基础上通过 ​**千亿级参数规模**、**海量无监督数据训练**​ 及 ​**指令微调/人类反馈强化学习（RLHF）​**​ 实现突破，具备三大核心能力：
- **涌现能力**​：解决未训练任务；
- **上下文学习（In-context Learning）​**​：通过示例泛化任务；
- **指令理解与流畅生成**​：逼近通用人工智能（AGI）目标。

# 二、 书籍结构与内容
## 基础知识
目录结构：
- [[第一章 NLP基础概念]]  ｜
- [[第二章 Transformer架构]]
- [[第三章 预训练模型]]
- [[第四章 大语言模型]]
- [[第五章 动手搭建大模型]]
- [[第六章 大模型训练流程实践]]
- [[第七章 大模型应用]]

(./docs/第一章%20NLP基础概念.md)
