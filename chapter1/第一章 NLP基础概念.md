## 第一章 NLP基础概念
---

## 一、什么是NLP
---
NLP 是 一种让计算机理解、解释和生成人类语言的技术。
Task：核心任务是通过计算机程序来模拟人类对语言的认知和使用过程。
现存挑战：处理歧义、理解抽象概念、处理隐喻和讽刺

## 二、NLP发展历程
---
早期规则基础方法--统计方法--ML/DL
**早期探索阶段**：（1940--1960）
二战后，一种语言自动翻译成另外一种语言。艾伦·图灵--图灵测试
- 该阶段机器翻译系统：以来字典查找和基本词序规则翻译

**符号主义与统计方法** ：（1970--1990）
1970: 逻辑基础的范式和自然语言理解。该阶段研究在符号主义/统计方法。
- 符号主义：形式语言和生成语法
- 统计方法：统计和概率方法
1980: 统计模型开始取代复杂的“手写”规则

**机器学习和深度学习** ：（2000--）
深度学习模型如循环神经网络（Recurrent Neural Network，RNN）、长短时记忆网络（Long Short-Term Memory，LSTM）和注意力机制等技术被广泛应用于 NLP 任务中。
2013: Word2Vec模型提出开创了词向量时代，提供国家有效的文本表示方法
2018: BERT模型引领预训练语言模型新时代
Transformer模型，通过大量参数，实现生成高质量的文本

## 三、NLP任务
---

#### 1. 中文分词（CWS）
Chinese Word Segmentation

中文不同英文有空格间隔，所以CWS是中文文本处理的首要步骤。
目的，连续中文文本Seg为有意义的词汇序列

注意：“，”“。”为单独Seg

正确分词作用：词性标注、实体识别、句法分析等

#### 2. 子词切分
Subword Segmentation

NLP领域一种常见的文本预处理技术，将词汇进一步分解为更小单元，即子词

子词作用：适用于处理词汇稀疏问题，理解未遇到的新词
核心是利用了英语单词**词根**

```
输入：unhappiness

不使用子词切分：整个单词作为一个单位，输出：“unhappiness”
使用子词切分（假设BPE算法）：单词被分割为：“un”、“happi”、“ness”
```

#### 3. 词性标注（POS）
Part-of-Speech Tagging

NLP领域一项**基础**任务
分配词性：英文的名词（Noun，N）、动词（Verb，V）、形容词（Adjective，Adj）等

作用：利于理解句子结构、进行句法分析、语义角色标注等高级NLP任务

作用于信息提取、情感分析、机器翻译
``**Question：那语意分析和这个的关系？**

词性标注使用了机器学习模型，隐马尔可夫模型HMM、条件随机场CRF或者深度学习的循环神经网络RNN、长短时记忆网络LSTM等。模型通过学习大量标注数据来预测新句子中每个单词的词性。

#### 4. 文本分类
Text Classification

NLP领域一项**核心**任务
将给定的文本自动分配到一个或多个预定义的类别中。
``Quesion：聚类同理？

文本分类关键在于理解文本的含义和上下文，并基于此文本映射到特定的类别。

```
# 新闻分类
文本：“NBA季后赛将于下周开始，湖人和勇士将在首轮对决。”
类别：“体育”

文本：“美国总统宣布将提高关税，引发国际贸易争端。”
类别：“政治”

文本：“苹果公司发布了新款 Macbook，配备了最新的m3芯片。”
类别：“科技”
```

**文本分类执行**的关键在于选择合适的**特征表示**和**分类算法**，高质量数据。

#### 5. 实体识别（NER）
Named Entity Recognition，命名实体识别

NLP领域的一项**关键**任务
自动识别文本中具有特定意义的实体，并将它们分类为预定义的类别

作用：用于信息提取、知识图谱构建、问答系统、内容推荐等，帮助系统理解文本中的关键元素及其属性

```
输入：李雷和韩梅梅是北京市海淀区的居民，他们计划在2024年4月7日去上海旅行。

输出：[("李雷", "人名"), ("韩梅梅", "人名"), ("北京市海淀区", "地名"), ("2024年4月7日", "日期"), ("上海", "地名")]
```

#### 6. 关系抽取
Relation Extraction

NLP领域的一项**关键**任务。
从文本中是识别实体之间的语义关系。
关系有：因果关系、拥有关系、亲属关系、地理位置关系等。

作用：用于理解文本内容、构建知识图谱、提升机器理解语言的能力等。

```
输入：比尔·盖茨是微软公司的创始人。

输出：[("比尔·盖茨", "创始人", "微软公司")]
```

#### 7. 文本摘要
Text Summarization

NLP领域的一项**重要**任务。
生成一段简介准确的摘要，概括原文的主要内容。

根据生成方式不同分为：抽取式摘要（Extractive Summarization）和生成式摘要（Abstractive Summarization）。

抽取式摘要：
- 原理：选取**原文**关键句子或词语组成摘要。
- 优点：原文信息，准确性高
- 缺点：容易出现不流畅
生成式摘要：
- 原理：不仅选取文本片段，还进行片段的重新组织和改写，并生成新的内容，需要深度理解原文，并且生成新的片段表达原有意思
- 优点：更加符合语意
- 缺点：需要更加复杂的模型，如：基于注意力机制的序列到序列模型（Seq2Seq）

作用：信息检索、新闻推送、报告生成等领域。可以实现快速获取文本的核心信息，节省阅读时间，提高信息处理效率。

#### 8. 机器翻译（MT）
Machine Translation

NLP领域的一项**核心**任务
将一种自然语言（源语言）自动翻译成另外一种自然语言（目标语言）的过程

不仅词汇转换，需要传达语言文本的语义、风格和文化背景等。最终实现准确和流畅的翻译。

基于神经网络的Seq2Seq模型、Transformer模型等，这些模型能够学习到源语言和目标语言之间的复杂映射关系。

#### 9. 自动问答（QA）
Automatic Question Answering

NLP领域的一项**高级**任务
理解自然语言问题，并且根据数据源自动提供准确的答案。模拟人类理解和回答问题能力，涵盖从简单的事实查询到复杂的推理和解释。

QA系统构建涉及：多个NLP子任务，如信息检索、文本理解、知识表示和推理等

自动问答大致可分为三类：检索式问答（Retrieval-based QA）、知识库问答（Knowledge-based QA）和社区问答（Community-based QA）。
- 检索式问答：通过搜索引擎等方式从大量文本中检索答案
- 知识库问答：通过结构化的知识库来回答问题
- 社区问答则依赖于用户生成的问答数据，如问答社区、论坛等

## 四、文本表示的发展历程
---
目的：人类语言转化为计算机可以处理的形式，文本数据数字化。
NLP领域的一项**基础和必要**工作。
**直接影响决定NLP系统的质量和性能。**

文本表示：文本中的语言单位（如字、词、短语、句子等）、单元关系、单元结构信息--转换-->计算机能处理的向量、矩阵、其他数据结构
作用于保留足够的语义信息，利于NLP任务，如：文本分类、情感分析、机器翻译等。

发展历程：规则方法-->统计学习方法-->深度学习技术-->
### 1. 词向量

### 2. 语言模型

## 3. Word2Vec

## 4. ELMo

