# 理解大模型的概念：生成式
---

## 新旧AI技术差异
---
传统AI技术
- 基于规则或特定算法，具备可解释性，有明确的input->output路径
- 智能输出投入的数据，无法创造新内容
- 它的计算和理解过程可循
生成式AI技术
- 基于大语言模型，黑箱模型不可解释，不是input->output逻辑
- 可以产出不存在的内容
- 它的计算和理解过程可循

## 生成式AI如何“生成”的
---
### 1. 参数：权重、属性、...
- 数学中的概念：基于多个数据拟合得到“权重”和“偏置”
-  大模型的核心参数，表彰了模型根据输入数据得出输出数据的能力
- 大模型的最终参数量，由模型的多层累加
`y=wx+b`

### 2. Token：词汇表
- 模型的最小单元，词元（词汇表）、字/词、像素点/片、声音
- GPT-3有50,257个Token
- 国内开源大模型均为公开Token数量
- 国内大模型训练设计到Token汉字化问题，分词方法不同，导致1Token->汉字对应关系不固定
- 附：OpenAI的[Token Tool](https://platform.openai.com/tokenizer)可以查看句子如何被汉化

9.8和9.11的大小AI无法理解原因，因为Ai是通过Token去理解语言的
### 3. Embedding：嵌入-向量化
每个单词标记序号的工作
一个词的一次向量化即为一个维度（属性）
GPT-3有12288个维度
12288个维度怎么来的？
语料库给了模型进行预训练，生成一堆维度（特征）（隐藏层维度）；当你再输入的词属于语料库里的词，那么会根据已理解的内容去进行计算生成。
为什么用向量化？
向量化能够计算两者之间相似度

词的向量，先随机生成（假设某一个维度）
之后去计算调整所有词的最合适向量（关系，去寻找角度）
如何算的？用Transformer进行NLP。

### 4. Transformer和上下文长度
Tansformer诞生于NLP，但是后来用于多个领域使用，不仅仅是NLP
一个词在上下文中，会富集了上下文的信息
因此，上下文给的token越多，其在当前语境下的清晰度越高
理论上上下文长度越长越好，但是超长的时候会导致过拟合，有些信息的权重不再产生作用。大模型的2K/8K等即为他所能接受的上下文长度。
### 5. 如何“生成”下一个Token
- 经过多层的参数权重进行优化后，Sam这个词对应的向量矩阵是包含上下文信息的
- 使用Sam这个最后的词，去算下一个词，哪一个词最有可能成为下一个词，输出的是全部成为下一个Token的权重值
- 转成概率，选择下一个词
	- 并不一定会选择概率最大的，随机性造就了“创意”
	- 多种选择方式，如temperature、Top_P

## 回顾
---


### 作业
---
### 使用我的话解释大语言模型生成内容的原理，200字以内
**我的**：
目前大语言模型生成内容的核心原理主要是通过理解了上下文的词向量，去推断出下一个词。其底层的原理是Transformer架构。
完整的一个过程是Embedding- Encoder-Decoder的过程。
- Embedding是把我们自然语言进行序列处理，生成带有序列信息、独立词向量的预料库。
- Encoder是让独立的词向量能够包含住（上下文语义+词属性/特征）的一个过程。
- Decoder就是利用Encoder所output的内容进行推断生成下一个词，具体是通过当前词去预测最高概率生成的下一个词。
这是目前我们所熟悉的大语言模型生成内容的底层原理。

**AI点评**
如果将这个题目放在AI产品经理的面试中，满分100分，**你的回答可以拿到80-85分**。
**失分点/可提升空间 (为什么没拿到90分以上):**
1. **技术模型的时效性 (-10分):** 回答中提到的“Embedding-Encoder-Decoder”是完整Transformer架构，它在机器翻译等任务中非常经典。但是，当前市面上绝大多数以内容生成为主的大语言模型（如GPT系列、Llama系列）采用的是**“Decoder-only”架构**。一个更精准的回答会点出这一点。虽然这不是致命伤，但对于追求卓越的候选人来说，这个细节能体现你对前沿技术的追踪深度。
2. **缺少产品视角的延伸 (-5分至-10分):** 你的回答是一个非常好的“技术科普”，但产品经理的面试更希望看到你**从技术原理引申到对产品的影响**。如果能在解释完原理后，加上一两句类似下面的话，分数会立刻冲上90分：
    - “……正因为是基于概率预测下一个词，所以模型有时会产生‘幻觉’，编造事实，这是我们在设计产品时需要通过检索增强（RAG）等方式来解决的。”
    - “……这个生成机制也解释了为什么调整Temperature（温度）参数可以控制内容的多样性，因为我们实质上是在调整选择下一个词的概率分布。”

>标准答案：
大语言模型生成内容的原理，本质上是一个**基于上下文的、序列化的概率预测游戏**。（“概率接龙”，而非“事实查询”）
首先，模型通过**Embedding**把我们输入的文字转换成它能理解的、包含语义和位置信息的数字向量。
其次，其核心是**Transformer架构**（特别是目前主流的Decoder部分）。它通过一个叫做‘自注意力机制’（Self-Attention）的关键技术，去计算文本中每个词与所有其他词的关联程度，从而深刻理解整个上下文。
最后，在生成时，模型会根据已经理解的全部上下文，**预测出下一个最有可能出现的词**，然后把这个新生成的词加入到上下文中，再循环往复地预测下一个词，最终形成完整的句子。
作为产品经理，理解这个原理很重要，因为它直接关系到产品的优缺点，比如为什么模型会一本正经地胡说八道（幻觉），以及为什么我们需要设计Prompt Engineering来更好地引导它在巨大的概率空间里找到我们想要的答案。

回答关键：核心原理、技术理解、**产品思维切换**

### 基于大语言模型生成内容的原理，举一个在产品中应用的示例，解释原因。
拼写错词纠正，如何纠错的：
- 理解上下文的词向量，判断当前词的落在此处位置的概率。

邮箱的“一键回复”、“帮我写”
“一键回复”
- 阶段1:输入处理与意图分类
	- 数据清洗：系统接受原始邮件的文本->去处HTML标签、CSS样式、图片、页脚签名档、引用的历史邮件等“噪音”，只保留最核心的邮件正文内容
	- 意图识别：系统使用一个“轻量级、专业训练的分类模型”进行邮件意图识别->分类后打标签`[会议邀请]`、`[问题询问]`、`[任务请求]`、`[信息确认]`等->后续生成任务就会标称明确目标的“填空”
- 阶段2:动态指令构建
	- if意图为`[会议邀请]`，其Prompt为： `“这是一封会议邀请邮件：‘[邮件正文]’。请生成三种不同态度的回复：1. 欣然接受；2. 礼貌拒绝；3. 询问更多信息。要求简短，在10个词以内。”`
	- if意图为`[问题询问]`，其Prompt为：`“这是一封问题咨询邮件：‘[邮件正文]’。请生成三种回复：1. 给予肯定答复；2. 表示需要查询后回复；3. 表示自己不清楚。要求简短，语气专业。”`
- 阶段3:LLM推理与生成
	- 大语言模型接受意图识别后的Prompt
	- 根据指令快速生成符合要求的多个候选答案
	- 例如，对于会议邀请的Prompt，它可能会生成：`["很高兴参加！", "非常抱歉，我那个时间有冲突。", "能发一下会议议程吗？"]` 等等。
- 阶段4:后处理与展示
	- 内容过滤：系统会对LLM生成内容进行最后一道检查，比如去处重复的、不通顺的、或者可能引起误解的回复（预设敏感词、黑名单等过滤攻击性、歧视性、不雅或非法词汇的词句->分类器（轻量化机器学习模型）去判断句子的“毒性”或“冒犯性”程度->个人身份信息检测进行防止信息泄漏->质量过滤器）
	- 多样性选择：确保提供给用户的三个选项在语义上是不同的，覆盖最常见的几种反应（进行文本向量化，把多个“答案”进行向量化->进行相似度计算->语义相似进行质量筛选（置信度）
	- 界面呈现：最终将这三条最优的回复作用可点击的按钮，展示在用户界面上。
如何生成回复多样化“答案”：
- Prompt明确输出的数量
- 调用API的时候设置解码策略（Decoding）
	- 要求模型一次性返回n个不同的高质量答案
	- 束搜索，让其每一步不会只选择概率最高的词（理解为温度）
	- 多样性乘法：调用API的时候设置重复惩罚、多样性的参数，鼓励模型在束中探索更多“答案”。