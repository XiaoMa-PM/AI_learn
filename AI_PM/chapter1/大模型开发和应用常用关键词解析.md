# 大模型开发和应用常用关键词解析
---
## 参数规模
不是参数规模越大越好
- 千亿是个分界线，之下不能打，之上没什么改进
- 参数规模越大，推理成本越大，对服务器配置要求越高
![](inbox/Pasted%20image%2020250909091706.png)

## 上下文长度
- 相同参数规模的模型，不太上下文长度（8K、32K、128K）的版本性能没差
	- 更大上下文长度的模型调用起来响应慢是你的幻觉...
	- 价格不同是因为配置不同的资源（训练成本也不一样）
- 你可以把上下文长度理解为“记忆力”
	- 参数=博闻
	- 上下文长度=强知
- 大部分大模型API定价都是按照输入/输出长度来定价的
	- 输出比输入贵（原因：输出需要回溯上下文，输入越来越多大模型消耗越大）
![](inbox/Pasted%20image%2020250909092037.png)

[国内外AI大语言模型API价格对比 \| AI排行榜官网 - AIGCRank.cn](https://aigcrank.cn/llmprice)

## 微调
- 对大模型进行“知识”定制
	- LoRA微调：通过在现有权重矩阵中添加低秩（行）矩阵来调整模型，可以在增加少量负担情况下有效调整模型。仅增加少量参数，参数效率高；资源利用少，训练周期短
	- 全参数微调：调整预训练模型的所有参数以获得新模型。允许对模型进行全面调整，更好地适应新任务；在有足够数据和计算资源的情况下，更有可能达到最佳性能
- 微调关键：优质数据集
	- 提示词+预期答案
- 产品工作：数据清洗
![](inbox/Pasted%20image%2020250909093422.png)

- 微调平台
	- ChatGLM：
	- 阿里百炼云：

## 其他概念
- Function Calling
- Tool Use
- Open AI
- JSON Mode及其他表述
- Partial Mode及其他表述
- 上下文缓存价格
