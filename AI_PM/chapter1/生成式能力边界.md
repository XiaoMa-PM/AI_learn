# 生成式能力边界
---

## 能力边界一：推理和计算能力缺失
---
### 1. 大模型不具备真正的推理能力
- 大模型只有“生成”，不存在“回答”、“思考”
	- 一次智能生成1个token，线性向前。无法回顾推演纠错。
	- 下一个Token的选择基于“概率”和“随机性”
	- “推理”需要环环相扣，兼顾、汇总所有“线索”
	- 大模型可能跳过“过程”。直接按“概率”给出最终的结果，甚至本来“猜对”结果了，因为“随机性”导致选择了错误的方向
- 可以做一些简单的“单向推理”
	- 要求大模型输出过程指标，即，输出所有用来支撑最终结果的“推理”语料，增加最终结果的准确性
	- e.g. 使用GPS目标文案大纲写创意文案的提示词
![](inbox/Pasted%20image%2020250831205816.png)

### 2. 大模型无法完成基本的数学计算
- 数字、数学符号等在Tokenization的过程中，可能被切的体无完肤
	- 最典型的9.11和9.8谁大？
- 大多数数学计算过程无法通过“生成式”完成
	- 现有大模型计算是通过已有的，曾经计算过来直接生成答案![](inbox/Pasted%20image%2020250831210155.png)
- 大模型依据已有“记忆”猜答案，数学只有99乘法口诀背的
目前GPTo1通过selfplay和RAG实现计算能力

## 能力边界二：幻觉问题和纠错失能
---
### 1. 幻觉问题来自于大模型“知识”的事实不相关
- 大模型没有知识，只有符合某种相关性的“夹角”关系
- 只要“关系不错”就可以用来放在下一个词的位置上
- 大模型不考虑事实、没有对错、没有价值观，只有放在这个位置是否合理的概率判断
- e.g. “林黛玉到拔垂杨柳”
	- 林黛玉（人物）->葬花（植物）->红楼梦（四大名著）
	- 鲁智深（人物）->垂杨柳（植物）->水浒（四大名著）
- 同人类的记忆错乱“幻觉”
### 2. 犯过的错误在上下文中持续“污染”后续工作
- 一整段完全**错误的信息**放在上下文里，是对**相关性的巨大污染**
	- 你的“纠错”指令在各个注意力层编码过程中有多大权重未知
	- 你的“纠错”指令可能不在「错误答案」生成的语言体系里，直接被忽视了
- 同理，“预防”犯错也不是有效的**提示词方法**
	- e.g.不要XXX，禁止XXX
		- “不要”、“禁止”可能没起到作用
		- “不要”、“禁止”的补集不明确（不要一路向北=向南、向西、向东；绕路向北？）

## 能力边界三：响应和知识的实时性
---
### 1. 流式输出无法解决实时响应问题

### 2. 实时的知识补齐连百度都做不到

## 能力边界四：用户带来的不确定性
---
### 1. 用户认知带来的能力边界

### 2. 用户表达带来的不稳定性

