{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b35a7e3",
   "metadata": {},
   "source": [
    "# 第三章 大语言模型基础\n",
    "## 语言模型与Transformer架构\n",
    "N-gram到RNN\n",
    "核心：LM是自然语言处理的核心\n",
    "目的：计算词序概率\n",
    "\n",
    "N-gram模型：（基于马尔可夫假设，第n个词与前面n+1个词有关）\n",
    "    基于统计的模型，假设当前词只依赖于前n-1个词\n",
    "    公式：P(w_i|w_1,w_2,...,w_i-1) = P(w_i|w_i-n+1,w_i-n+2,...,w_i-1)\n",
    "痛点：\n",
    "    - 数据稀疏：未出现的词组出现则概率为0；\n",
    "    - 泛化能力差：无法理解词语的“含义”，无法实现词义关联。\n",
    "\n",
    "神经网络语言模型（NNLM）局限性：\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
