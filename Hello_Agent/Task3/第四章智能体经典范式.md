# 第四章 智能体经典范式
## 构建llm客户端
### 所需依赖
import openai
import os
import dotenv
import typing

### `llm_client` 的核心作用

`llm_client` 就是你项目里**“调用大模型的统一入口”**：把各种模型/平台的调用细节（key、地址、参数、流式输出、错误处理）都藏起来，让上层 Agent 只管“给 messages → 拿文本”。

```text
┌─────────────────────────────────────────────────────────┐
│                     上层：Agent / 业务代码               │
│  例：think(messages, temperature=0)                      │
└─────────────────────────────────────────────────────────┘
                      │
                      │ 1) 传入 messages（上下文/历史/指令）
                      ▼
┌─────────────────────────────────────────────────────────┐
│                    llm_client（统一封装层）              │
│  目标：屏蔽调用细节，让上层只面对一个接口                │
└─────────────────────────────────────────────────────────┘
                      │
                      │ 2) 读取配置/初始化客户端
                      │    - model 名称
                      │    - API Key（常来自环境变量）
                      │    - base_url（可选：不同平台）
                      │    - 默认参数（temperature/max_tokens等）
                      ▼
┌─────────────────────────────────────────────────────────┐
│                  构造请求（标准化入参）                   │
│  - model=self.model                                     │
│  - messages=messages                                    │
│  - temperature=temperature                              │
│  - stream=True / False    # 设置流式                     │
└─────────────────────────────────────────────────────────┘
                      │
                      │ 3) 调用模型 SDK / HTTP
                      ▼
┌─────────────────────────────────────────────────────────┐
│                 LLM Provider（OpenAI/其它）              │
│           chat.completions.create(...) 返回响应          │
└─────────────────────────────────────────────────────────┘
                      │
          ┌───────────┴────────────────┐
          │                            │
          │ 4A) 非流式（一次性返回）    │ 4B) 流式（逐块返回）
          │                            │
          ▼                            ▼
┌───────────────────────┐     ┌───────────────────────────┐
│ response.message...    │     │ response 是 iterator       │
│ content = 完整文本     │     │ for chunk in response:     │
└───────────────────────┘     │   delta.content（增量token）│
          │                    │   print（可选）             │
          │                    │   append 到 collected       │
          │                    └───────────────────────────┘
          │                            │
          └──────────────┬─────────────┘
                         │
                         │ 5) 错误处理/重试（可选）
                         │    - 超时、网络错误
                         │    - 解析异常
                         ▼
┌─────────────────────────────────────────────────────────┐
│                 返回给上层：最终字符串 text              │
└─────────────────────────────────────────────────────────┘

```

### llm_client产品能力
- 统一入口
- 配置与密钥管理
- 参数治理（可控性）
- 流式输出
- 错误处理
- 可替换性

### 使用Vibe Coding的PROMPT
`llm_client `作为一个“基础组件”写清楚：
输入：messages + 参数（temperature/stream）
输出：text（字符串）+ 可选 token 事件（用于实时展示）
非功能：可替换模型、错误不崩、日志可查
- 支持模型切换
- 自动重试
- 失败回退（fallback）
- 统计token用量（成本）

## 经典范式-ReAct
> 动态决策循环
> ReAct之前，主流模式是采用CoT（Chain of Thought）和ToT（Tree of Thoughts）引导模型进行推理，但这些方法是进行单论对话推理，且无法与外部更多信息连接，从而容易出现幻觉。

### ReAct原理
Thought → Action → Observation

解决了三个经典问题：
- 不知道自己不知道
- 不会使用外部工具
- 出错不会修正

```text
┌──────────────┐
│   用户问题    │
└──────┬───────┘
       │
       ▼
┌─────────────────────────┐
│   Thought（模型思考）    │
│  · 分析问题              │
│  · 判断是否需要工具      │
└──────┬──────────────────┘
       │
       ▼
┌─────────────────────────┐
│   Action（模型决策）     │
│  · Search[...]           │
│  · Calculator[...]       │
│  · Finish[...]           │
└──────┬──────────────────┘
       │
       ▼
┌─────────────────────────┐
│ Observation（真实世界） │
│ · 工具执行结果           │
│ · 错误 / 数据 / 文本     │
└──────┬──────────────────┘
       │
       ▼
┌─────────────────────────┐
│   写入 History           │
│   作为下一轮上下文       │
└──────┬──────────────────┘
       │
       ├── 未完成 → 回到 Thought
       │
       └── 完成 → Finish[最终答案]

```

### 应用场景
- 需要外部知识任务
- 需要精确计算的任务
- 需要与API交互的任务

## `tools.py` 组成
> 工具def+执行器类

### 定义工具`tools`(方法)
一个工具核心要素：
- name：让Agent在`Action`中识别调用
- Description：描述工具能做什么，输入什么，输出什么
- Parameters：工具的参数，包括参数名、类型、是否必填、描述等
- Execution Logic：工具的执行逻辑、方法或函数
定义时，需确定调用的工具传入与传出内容，通常采用params为传入，client为执行工具，results为输出结果

### 构建工具执行器`ToolExecutor`（类）
核心完成三个事项：
- registerTool(name, description, func)：注册工具
- getTool(name)：按名字拿到可执行函数
- getAvailableTools()：把所有工具的描述拼成字符串，塞进 prompt 里

## ReAct组成
1. 系统提示词设计
2. 核心循环ReActAgent实现
3. 输出解析器的实现
4. 工具调用与执行
5. 观测结果的整合
6. 运行实例与分析

### 系统提示词设计
> 动态插入可用工具、用户问题以及中间步骤的交互历史
```python
# ReAct提示词模板
REACT_PROMPT_TEMPLATE = """
你是一个有能力调用外部工具的智能体。

可用工具如下：
{tools}

请严格按照以下格式进行回应：

Thought：你的思考过程，用于分析问题、拆解任务和规划下一步行动。
Action：你决定采取的行动，必须是以下格式之一：
- `{{tool_name}}[{{tool_input}}]`:调用一个可用工具。
- `Finish[最终答案]`：当你认为已经获得最终答案时。
- 当你收集到足够信息，能够回答用户的最终问题时，你必须在Action：字段后使用 Finish[最终答案] 来输出最终答案。

Now，Please begin to solve the following question:
Question：{question}
History：{history}
"""
```

The template defines the interaction between the agent and LLM:
- 角色定义：设定了LLM的角色。
- 工具清单（{tools}）：动态告知LLM它有哪些可用的工具。
- 格式规范约束（Thought/Action）：这是ReAct的核心，强制LLM输出具有结构性，使其通过代码精确解析其意图。
- 动态上下文（{question}/{history}）：动态注入原始问题与交互历史，让LLM基于完整的上下文进行决策。

### 核心循环ReActAgent实现
`ReActAgent`类，构建“格式化提示词 -> LLM -> 执行动作 -> 整合结果”，直到任务完成或达到`max_steps`最大步数限制：
- `_init_`：初始化参数，包括：LLM客户端、Tool执行器、最大步数
- `run`：主循环，处理用户输入，调用工具，更新历史，while循环

此处设计上ReActAgent可以直接输入：
- 所需的模型
- 所需的工具
- 最大步数
- 用户问题
而直接输出结果。

### 输出解析器的实现🧩
`ReActAgent`类中的方法，用于解析LLM输出（LLM输出为纯文本，需要从中提取出`Thought`和`Action`内容），HelloAgent使用了正则表达式实现。
- `_parse_output`：使用正则表达式提取return出thought与action。
- `_parse_action`：使用正则表达式提取出action中的tool（进一步解析action字符串）

**什么是“正则表达式”？**
> 从一堆文字按规则寻找内容
> 课程中的正则表达式主要是两个目的：
>     - 语义切割：划分thought、action
>     - 行动结构化：用哪个tool、输入工具的input

`text` = LLM输出的完整文本字符串
通过`_parse_output`输出`（thought，action）`

```python
thought_match = re.search(
    r"Thought:\s*(.*?)(?=\nAction:|$)",
    text,
    re.DOTALL
)
```
正则表达式内容：
- \s = 空白字符（空格、换行）
- * = 0次或多次
- (.*?)：
    - () = 表示要抓取这部分
    - . = 任意字符
    - * = 任意多个
    - ? = 尽量少地匹配
- (?=\nAction:|$)：
    - 直到出现“Action”或“字符串结束”
    - ?= 意为判断，出现该内容后就停止匹配，并不添加进入。
- re.DOTALL可以匹配换行，即提取出的结果包含多行。

```python
thought = thought_match.group(1).strip()
```
- group(1)：拿第一个括号里的内容（也就是 (.*?)）
- strip()：去掉前后空格/换行

> parse正则最终在`run`中运行实现，内部Agent执行流程封装在外部调用的`run`上。

使用流程
- tools中添加工具
- ReAct中的main添加工具的desc、tool_executor
- 在初始化agent中设置max_steps=10

### 工具调用与执行
从首次llm返回的text -> str 中提取thought、action。
- 先if判断是否有thought，若不存在则`break`
- 再if判断action是否为`Finish`，若是则提取最终答案，return结果
- 没有输入action`Finish`则执行tool_name与tool_input提取，调用tool_executor执行工具，将结果作为observation
> 此处判断`Finish`用了一个startswith进行判断“一个字符串是否以某个内容开头”，如果是则返回True，不是则为False🧩

### 观测结果的整合
将observation整合到history中，作为下一次llm的输入，继续循环
- 提供历史记录
- 下一轮的上下文
> 该`history`仅记录当前ReAct循环中发生事情，并非多轮对话记忆、长期知识记忆、向量数据库

### ReAct核心特点与局限性
1. 高解释性：设置的`Thought`链，可以查看智能体思考
2. 动态规划与纠错能力：通过O-T-A-O进行纠错尝试
3. 工具协调：ReAct范式天然优势进行推理与外部工具结合
4. 局限性：
    - 依赖LLM自身能力：逻辑推理、指令遵守低温度、格式化能力
    - 执行效率：一个任务是独立的多次调用，消耗token大
    - 提示词脆弱：模板与用词差异易于导致输出格式不稳定而解析失败
    - 陷入局部最优解：步进式决策模式，导致智能体缺乏一个全局、长远规划，Observation往往只反映当前局部状态，可能错过更优的全局策略。

## Plan-and-Solve范式
> 算法层面：ReAct属于Greedy（贪心式）决策/Reactive Policy（反应式策略），Plan-and-Solve属于分阶段规划策略/Deliberative Policy（审慎规划策略）；
> ReAct的公式也表明其执行结果依赖history，而PaS依赖于Plan。
> ReAct只能执行一步后，先检查校验这一步后再下一步，会因为依赖history而陷入局部循环。
ReAct结构：
- 每一步由LLM控制
- 决策 → 执行 → 决策 → 执行
Plan-and-Solve结构：
- 第一阶段控制、第二阶段按流程执行
- 决策全集 → 执行

ReAct最明显的问题就是输出需要全部结构强关联的内容时，ReAct按顺序写，无法感知后续会书写什么内容。

### 原理
```markdown
用户问题
    ↓
【Planning 模型调用】
    ↓
生成：
["步骤1", "步骤2", "步骤3"]
    ↓
【Executor 执行】
    ↓
执行步骤1
执行步骤2
执行步骤3
    ↓
最终答案
```

### 应用场景
- 多步骤数学应用题：列出计算步骤，逐一求解
- 需要整合多信息源的报告撰写：需要规划报告结构，逐一填充内容
- 代码生成任务：需要先构思好函数、类和模块结构，再逐一实现

### Plan-and-Solve组成
1. 系统提示词设计
2. 核心规划器Planner实现
3. 执行器Executor（执行与状态管理）
4. 运行实例与分析

### 提示词设计
> 问题传入、python列表格式输出任务

规划阶段sys提示词：
```python
EXECUTOR_PROMPT_TEMPLATE = """
你是一位顶级的AI执行专家。你的任务是严格按照给定的计划，一步步地解决问题。
你将收到原始问题、完整的计划、以及到目前为止已经完成的步骤和结果。
请你专注于解决“当前步骤”，并仅输出该步骤的最终答案，不要输出任何额外的解释或对话。

# 原始问题:
{question}

# 完整计划:
{plan}

# 历史步骤与结果:
{history}

# 当前步骤:
{current_step}

请仅输出针对“当前步骤”的回答:
"""

```
提示词设计要点与逻辑：
- 角色设定：AI规划专家，给予模型能力边界
- 任务描述：清晰定义“分解问题”目标
- 格式约束：强约束输出格式Python列表格式的字符串，简化后续代码解析工作（与模型能力也有关联）

执行阶段提示词：
```python
EXECUTOR_PROMPT_TEMPLATE = """
你是一位顶级的AI执行专家。你的任务是严格按照给定的计划，一步步地解决问题。
你将收到原始问题、完整的计划、以及到目前为止已经完成的步骤和结果。
请你专注于解决“当前步骤”，并仅输出该步骤的最终答案，不要输出任何额外的解释或对话。

# 原始问题:
{question}

# 完整计划:
{plan}

# 历史步骤与结果:
{history}

# 当前步骤:
{current_step}

请仅输出针对“当前步骤”的回答:
"""
```

提示词设计要点与逻辑：
- 角色设定：AI执行专家，给予模型能力边界
- 输入描述：原始问题、完整计划、当前步骤与结果
    - 原始问题：确保模型了解最终目标
    - 完整计划：让模型了解当前步骤在整体任务为位置
    - 历史步骤与结果：提供至今为止已经完成的工作，作为当前步骤的直接输入
    - 当前步骤：明确提示模型现在需要解决哪一个具体任务
- 任务描述：聚焦当前步骤回答
- 内容约束：不输出任何额外解释与对话

### 规划器`Planner`类组成
> 生成计划蓝图
__init__：输入llm_client客户端
plan方法：输入问题，输出list列表[str]字符串行动计划
- 读取计划提示词
- 记录计划的消息列表
- 流式输出获取计划
- 解析LLM输出的列表字符串

### 执行器`Executor`类、`PlanAndSolveAgent`类组成
> 按计划执行，调用llm与状态管理
`Executor`类
__init__：输入llm_client客户端
execute方法：输入问题、list[str]列表计划
- history存储历史步骤和结果字符串
- 循环执行任务plan中的每一个步骤
    - 读取执行提示词内容：question、plan、history、current_step
    - 定义messages消息列表，输入：user提示词
    - response接受llm流式输出文本
    - 更新历史记录（step+response），组成答案
- 循环结束返回final_answer

`PlanAndSolveAgent`类
__init__：输入llm_client客户端
- llm_client注册
- planner注册类
- executor注册类
run方法：输入问题
> 承担执行逻辑：先规划、后执行
- 调用planner.plan()获取计划到plan变量
- if逻辑检查plan计划是否有效生成
- 调用executor.execute(question, plan)执行计划
- 返回最终答案

> 该类设计逻辑体现：组合优先于继承

### 运行实例与分析
设计上直接调用PlanAndSolveAgent的run方法
输入：问题
输出：python计划列表、执行过程输出、最终答案

## Reflection范式
> 解决问题：模型输出答案错误不可见、局部正确掩盖整体逻辑错误、长链任务误差放大。核心解决局部最优化问题，实现全局最优。
> 核心思想：让模型自己检查自己逻辑与策略，判断是否需要修正
> 构建了临时的“短期记忆”，该记忆系统还能服务于**多模态**输出使用。
> 为什么第二次推理会发现第一次没发现的错误：
> - 第一次推理为前向生成
> - 第二次推理为反向推导检查
> 两者的注意力分布不一样

### 原理
> 工作流（循环）：执行 -> 反思 -> 优化
执行（Execution）：先由简单LLM/ReAct/Plan-and-Solve执行获得“初稿结果”
反思（Reflection）：多维度评估执行结果
- 事实性错误：是否存在与常识或已知事实相悖的内容
- 逻辑漏洞：推理过程是否存在不连贯或矛盾之处
- 效率问题：是否有更直接、更简洁的逻辑来完成任务
- 遗漏信息：是否忽略了问题的某些关键约束或方面。
根据评估，它会生成结构化的反馈，指出具体问题所在和改进建议。
优化（Refinement）：agent根据“初稿结果”与“反馈”作为新的上下文，再次调用大预言模型，要求它根据反馈内容对初稿进行修正，生成完善结果。

```markdown
flowchart TD

    Q[用户问题] --> R[ReAct循环执行]

    R --> A[初步答案]

    A --> Ref[Reflection检查]

    Ref --> |无错误| Final[最终输出]

    Ref --> |有错误| Fix[修正答案]

    Fix --> Final

```

### 应用场景
> 高价值 + 高复杂度 + 高错误风险 的任务
> 关键业务代码、技术报告、科学研究逻辑推演、深度分析和规划决策支持
- 多步骤复杂推理（长链任务）：数据证明、逻辑推理题、多约束优化问题、复杂流程设计
    - 检查逻辑跳步
    - 检查约束遗漏
    - 检查计算错误
- 高风险决策（加强可靠性）：医疗建议、法律解释、财务规划、企业战略分析
    - 检查事实性错误
    - 检查逻辑漏洞
    - 检查效率问题
    - 检查遗漏信息
- 生成型任务（质量优化）：写论文、写报告、写产品方案、写代码
    - 检查结构是否完整
    - 是否遗漏关键点
    - 是否存在逻辑矛盾
    - 是否有表达不清的地方
- 代码生成与Debug：生成 -> 运行 -> 报错 -> Reflection分析错误原因 -> 修复
- 多Agent协作中的质量控制
    - Solver负责解题
    - Critic负责审查

### 组成构件
1. 记忆模块Memory设计
2. 提示词实现（3个提示词）
    - 任务执行提示词
    - 任务反思提示词
    - 任务优化提示词
3. ReflectionAgent类封装（新增Memory模块）

### 记忆模块Memory设计
> 临时短期记忆，用于存储执行与反思过程中的关键信息，也是处理上一轮的LLM执行结果、反思的上下文供后续LLM使用
`Memory`类：
- __init__：初始化空列表`records`，按顺序存储每一次行动和反思；
- add_record：方法负责向记忆中添加新的条目；
- get_trajectory：类的核心方法，将记忆轨迹“序列化”成一段文本，可以直接插入到后续提示词中，为模型的反思和优化提供完整的上下文；
- get_last_execution：方便我们获取最新的“初稿”以供反思。

### 提示词实现
**任务执行提示词**
> 首次尝试降低解决问题的提示词，内容相对直接，只要求模型完成指定任务
> 输入：task
> 输出：code
```python
INITIAL_PROMPT_TEMPLATE = """
你是一位资深的Python程序员。请根据以下要求，编写一个Python函数。
你的代码必须包含完整的函数签名、文档字符串，并遵循PEP 8编码规范。

要求：{task}
请直接输出代码，不要包含任何额外的解释
"""
```

**反思提示词**
> 应用于对上一轮生成代码进行批判性分析（针对性能），并提供具体的、可操作的反馈
> 输入：task、code
> 输出：feedback
```python
REFLECT_PROMPT_TEMPLATE = """
你是一位严格的代码评审专家和资深算法工程师，对代码的性能有极致的要求。
你的任务是审查以下Python代码，并专注于找出其在<strong>算法效率</strong>上的主要瓶颈。

# 原始任务:
{task}

# 待审查的代码:
```python
{code}
```
请你分析该代码的时间复杂度，并思考是否存在一种<strong>算法上更优</strong>的解决方案来显著提升性能。
如果存在，请清晰地指出当前算法的不足，并提出具体的、可行的改进算法建议（例如，使用筛法替代试除法）。
如果代码在算法层面已经达到最优，才能回答“无需改进”。

请直接输出你的反馈，不要包含任何额外的解释。
"""
```

**优化提示词**
> 第二个执行层，收到反馈、上一轮执行结果，根据结果修正和优化原代码。
```python
REFINE_PROMPT_TEMPLATE = """
你是一个资深的Python程序员。你正在根据一位代码评审专家的反馈来优化你的代码。

# 原始任务:
{task}

# 你上一轮尝试的代码:
{last_code_attempt}
评审员的反馈：
{feedback}

请根据评审员的反馈，生成一个优化后的新版本代码。
你的代码必须包含完整的函数签名、文档字符串，并遵循PEP 8编码规范。
请直接输出优化后的代码，不要包含任何额外的解释。
"""
```

### ReflectionAgent类封装
__init__：初始化llm_client、memory、max_iterations
- 初始化llm客户端
- 初始化Memory类（记忆模块）
- 传入max_iterations数值
run程序：
- 初始执行：initial_prompt、initial_code、memory记录执行轨迹
- 迭代循环：
    - Reflection反思：last_code、reflect_prompt、feedback、memory记录执行轨迹
    - 判断是否中止：判断feedback是否带有"无需改进"，是则break循环
    - 优化：refine_prompt(task、last_code_attempt、feedback)、refine_code、memory记录执行轨迹
- final_code：记录最终“循环”执行结果
_get_llm_response：辅助方法，获取LLM完整的流式想要结果（此处区别ReAct和P-a-S，llm响应封装成方法调用）

### 运行实例分析
> 成本换质量的方案
- 输入：问题
- 输出：初始执行结果、评审过程、优化过程、最终执行结果

## 快速总结
- ReAct目的：环境适应调用根据、动态纠错、探索处理任务
- Plan-and-Solve：多步骤推理、结构性与稳定性优势，适合处理逻辑路径确定、内部推理密集任务
- Reflection：模型能力不足情况下，提升解决方案质量的一套模式

## 补充知识
### Prompt提示词类型
> hello-agent上没有去区分sys与user，直接将所有内容输入到user中
user prompt：用户输入
- 任务内容、上下文、历史记录
sys prompt：系统提示词
- 角色设定、任务描述、格式约束

提示词工程类型：
- 行为约束类
    - 必须输出JSON
    - 禁止编造
    - 只能使用提供的工具
> 通常为sys
- 任务分解类
    - 当前问题
    - 当前子任务
    - 当前步骤
> 通常为user
- 状态类
    - 历史执行结果
    - 上一轮输出
    - 工具观察结果
> 通常为user
- 格式控制类
    - 限定格式输出
> 常设置于sys或者user的规则段落

提示词设计要点：
- sys优先级高于user，在大模型内部，sys提示词权重更高
- sys承担固定，常常不被覆盖的内容
- user承担动态变化，动态调整内容

### 提示词中的{xxx}
{xxx}属于python的字符串格式化语法，str.format()占位符，prompt执行会通过.format()方法将xxx替换为实际值。
llm直接输入的并非{xxx}，而是替换后的字符串。
