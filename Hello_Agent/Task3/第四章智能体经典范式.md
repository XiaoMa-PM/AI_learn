# 第四章 智能体经典范式
## 构建llm客户端
### 所需依赖
import openai
import os
import dotenv
import typing

### `llm_client` 的核心作用

`llm_client` 就是你项目里**“调用大模型的统一入口”**：把各种模型/平台的调用细节（key、地址、参数、流式输出、错误处理）都藏起来，让上层 Agent 只管“给 messages → 拿文本”。

```text
┌─────────────────────────────────────────────────────────┐
│                     上层：Agent / 业务代码               │
│  例：think(messages, temperature=0)                      │
└─────────────────────────────────────────────────────────┘
                      │
                      │ 1) 传入 messages（上下文/历史/指令）
                      ▼
┌─────────────────────────────────────────────────────────┐
│                    llm_client（统一封装层）              │
│  目标：屏蔽调用细节，让上层只面对一个接口                │
└─────────────────────────────────────────────────────────┘
                      │
                      │ 2) 读取配置/初始化客户端
                      │    - model 名称
                      │    - API Key（常来自环境变量）
                      │    - base_url（可选：不同平台）
                      │    - 默认参数（temperature/max_tokens等）
                      ▼
┌─────────────────────────────────────────────────────────┐
│                  构造请求（标准化入参）                   │
│  - model=self.model                                     │
│  - messages=messages                                    │
│  - temperature=temperature                              │
│  - stream=True / False    # 设置流式                     │
└─────────────────────────────────────────────────────────┘
                      │
                      │ 3) 调用模型 SDK / HTTP
                      ▼
┌─────────────────────────────────────────────────────────┐
│                 LLM Provider（OpenAI/其它）              │
│           chat.completions.create(...) 返回响应          │
└─────────────────────────────────────────────────────────┘
                      │
          ┌───────────┴────────────────┐
          │                            │
          │ 4A) 非流式（一次性返回）    │ 4B) 流式（逐块返回）
          │                            │
          ▼                            ▼
┌───────────────────────┐     ┌───────────────────────────┐
│ response.message...    │     │ response 是 iterator       │
│ content = 完整文本     │     │ for chunk in response:     │
└───────────────────────┘     │   delta.content（增量token）│
          │                    │   print（可选）             │
          │                    │   append 到 collected       │
          │                    └───────────────────────────┘
          │                            │
          └──────────────┬─────────────┘
                         │
                         │ 5) 错误处理/重试（可选）
                         │    - 超时、网络错误
                         │    - 解析异常
                         ▼
┌─────────────────────────────────────────────────────────┐
│                 返回给上层：最终字符串 text              │
└─────────────────────────────────────────────────────────┘

```

### llm_client产品能力
- 统一入口
- 配置与密钥管理
- 参数治理（可控性）
- 流式输出
- 错误处理
- 可替换性

### 使用Vibe Coding的PROMPT
`llm_client `作为一个“基础组件”写清楚：
输入：messages + 参数（temperature/stream）
输出：text（字符串）+ 可选 token 事件（用于实时展示）
非功能：可替换模型、错误不崩、日志可查
- 支持模型切换
- 自动重试
- 失败回退（fallback）
- 统计token用量（成本）

## 经典范式-ReAct

> ReAct之前，主流模式是采用CoT（Chain of Thought）和ToT（Tree of Thoughts）引导模型进行推理，但这些方法是进行单论对话推理，且无法与外部更多信息连接，从而容易出现幻觉。

### ReAct原理
Thought → Action → Observation

解决了三个经典问题：
- 不知道自己不知道
- 不会使用外部工具
- 出错不会修正

```text
┌──────────────┐
│   用户问题    │
└──────┬───────┘
       │
       ▼
┌─────────────────────────┐
│   Thought（模型思考）    │
│  · 分析问题              │
│  · 判断是否需要工具      │
└──────┬──────────────────┘
       │
       ▼
┌─────────────────────────┐
│   Action（模型决策）     │
│  · Search[...]           │
│  · Calculator[...]       │
│  · Finish[...]           │
└──────┬──────────────────┘
       │
       ▼
┌─────────────────────────┐
│ Observation（真实世界） │
│ · 工具执行结果           │
│ · 错误 / 数据 / 文本     │
└──────┬──────────────────┘
       │
       ▼
┌─────────────────────────┐
│   写入 History           │
│   作为下一轮上下文       │
└──────┬──────────────────┘
       │
       ├── 未完成 → 回到 Thought
       │
       └── 完成 → Finish[最终答案]

```

### 应用场景
- 需要外部知识任务
- 需要精确计算的任务
- 需要与API交互的任务

## `tools.py` 组成
> 工具def+执行器类

### 定义工具`tools`(方法)
一个工具核心要素：
- name：让Agent在`Action`中识别调用
- Description：描述工具能做什么，输入什么，输出什么
- Parameters：工具的参数，包括参数名、类型、是否必填、描述等
- Execution Logic：工具的执行逻辑、方法或函数
定义时，需确定调用的工具传入与传出内容，通常采用papams为传入，client为执行工具，results为输出结果

### 构建工具执行器`ToolExecutor`（类）
核心完成三个事项：
- registerTool(name, description, func)：注册工具
- getTool(name)：按名字拿到可执行函数
- getAvailableTools()：把所有工具的描述拼成字符串，塞进 prompt 里

## ReAct组成
1. 系统提示词设计
2. 核心循环ReActAgent实现
3. 输出解析器的实现
4. 工具调用与执行
5. 观测结果的整合
6. 运行实例与分析

### 系统提示词设计
> 动态插入可用工具、用户问题以及中间步骤的交互历史
```python
# ReAct提示词模板
REACT_PROMPT_TEMPLATE = """
你是一个有能力调用外部工具的智能体。

可用工具如下：
{tools}

请严格按照以下格式进行回应：

Thought：你的思考过程，用于分析问题、拆解任务和规划下一步行动。
Action：你决定采取的行动，必须是以下格式之一：
- `{{tool_name}}[{{tool_input}}]`:调用一个可用工具。
- `Finish[最终答案]`：当你认为已经获得最终答案时。
- 当你收集到足够信息，能够回答用户的最终问题时，你必须在Action：字段后使用 Finsh[最终答案] 来输出最终答案。

Now，Please begin to solve the following question:
Question：{question}
History：{history}
"""
```

The template defines the interaction between the agent and LLM:
- 角色定义：设定了LLM的角色。
- 工具清单（{tools}）：动态告知LLM它有哪些可用的工具。
- 格式规范约束（Thought/Action）：这是ReAct的核心，强制LLM输出具有结构性，使其通过代码精确解析其意图。
- 动态上下文（{question}/{history}）：动态注入原始问题与交互历史，让LLM基于完整的上下文进行决策。

### 核心循环ReActAgent实现
`ReActAgent`类，构建“格式化提示词 -> LLM -> 执行动作 -> 整合结果”，直到任务完成或达到`max_steps`最大步数限制：
- `_init_`：初始化参数，包括：LLM客户端、Tool执行器、最大步数
- `run`：主循环，处理用户输入，调用工具，更新历史，while循环

此处设计上ReActAgent可以直接输入：
- 所需的模型
- 所需的工具
- 最大步数
- 用户问题
而直接输出结果。

### 输出解析器的实现🧩
`ReActAgent`类中的方法，用于解析LLM输出（LLM输出为纯文本，需要从中提取出`Thought`和`Action`内容），HelloAgent使用了正则表达式实现。
- `_parse_output`：使用正则表达式提取return出thought与action。
- `_parse_action`：使用正则表达式提取出action中的tool（进一步解析action字符串）

**什么是“正则化表达式”？**
> 从一堆文字按规则寻找内容
> 课程中的正则化主要是两个目的：
>     - 语义切割：划分thought、action
>     - 行动结构化：用哪个tool、输入工具的input

`text` = LLM输出的完整文本字符串
通过`_parse_output`输出`（thought，action）`

```python
thought_match = re.search(
    r"Thought:\s*(.*?)(?=\nAction:|$)",
    text,
    re.DOTALL
)
```
正则化内容：
- \s = 空白字符（空格、换行）
- * = 0次或多次
- (.*?)：
    - () = 表示要抓取这部分
    - . = 任意字符
    - * = 任意多个
    - ? = 尽量少地匹配
- (?=\nAction:|$)：
    - 直到出现“Action”或“字符串结束”
    - ?= 意为判断，出现该内容后就停止匹配，并不添加进入。
- re.DOTALL可以匹配换行，即提取出的结果包含多行。

```python
thought = thought_match.group(1).strip()
```
- group(1)：拿第一个括号里的内容（也就是 (.*?)）
- strip()：去掉前后空格/换行

> parse正则化最终在`run`中运行实现，内部agent执行流程封装在外部调用的`run`上。

使用流程
- tools中添加工具
- ReAct中的main添加工具的desc、tool_executor
- 在初始化agent中设置max_steps=10

### 工具调用与执行
从首次llm返回的text -> str 中提取thought、action。
- 先if判断是否有thought，若不存在则`break`
- 再if判断action是否为`Finish`，若是则提取最终答案，return结果
- 没有输入action`Finish`则执行tool_name与tool_input提取，调用tool_executor执行工具，将结果作为observation
> 此处判断`Finish`用了一个startswith进行判断“一个字符串是否以某个内容开头”，如果是则返回Ture，不是则为False🧩

### 观测结果的整合
将observation整合到history中，作为下一次llm的输入，继续循环
- 提供历史记录
- 下一轮的上下文
> 该`history`仅记录当前ReAct循环中发生事情，并非多轮对话记忆、长期知识记忆、向量数据库

### ReAct核心特点与局限性
1. 高解释性：设置的`Thought`链，可以查看智能体思考
2. 动态规划与纠错能力：通过O-T-A-O进行纠错尝试
3. 工具协调：ReAct范式天然优势进行推理与外部工具结合
4. 局限性：
    - 依赖LLM自身能力：逻辑推理、指令遵守低温度、格式化能力
    - 执行效率：一个任务是独立的多次调用，消耗token大
    - 提示词脆弱：模板与用词差异已于导致输出格式不稳定而解析失败
    - 陷入局部最优解：步进式决策模式，导致智能体缺乏一个全局、长远规划，Observation往往只反映当前局部状态，可能错过更优的全局策略。

## Plan-and-Solve组成
> 算法层面：ReAct属于Greedy（贪心式）决策，Plan-and-Solve属于Optimal（最优）决策；
> ReAct的公式也表明其执行结果依赖history，而PaS依赖于Plan。
> ReAct只能执行一步后，先检查校验这一步后再下一步，会因为依赖history而陷入局部循环。
ReAct结构：决策 → 执行 → 决策 → 执行
Plan-and-Solve结构：决策全集 → 执行

### 原理
```markdown
用户问题
    ↓
【Planning 模型调用】
    ↓
生成：
["步骤1", "步骤2", "步骤3"]
    ↓
【Executor 执行】
    ↓
执行步骤1
执行步骤2
执行步骤3
    ↓
最终答案
```

应用场景
构成的内容