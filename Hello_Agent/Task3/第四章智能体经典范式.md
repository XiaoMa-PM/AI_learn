# 第四章 智能体经典范式
## 构建llm客户端
### 所需依赖
import openai
import os
import dotenv
import typing

### `llm_client` 的核心作用

`llm_client` 就是你项目里**“调用大模型的统一入口”**：把各种模型/平台的调用细节（key、地址、参数、流式输出、错误处理）都藏起来，让上层 Agent 只管“给 messages → 拿文本”。

```text
┌─────────────────────────────────────────────────────────┐
│                     上层：Agent / 业务代码               │
│  例：think(messages, temperature=0)                      │
└─────────────────────────────────────────────────────────┘
                      │
                      │ 1) 传入 messages（上下文/历史/指令）
                      ▼
┌─────────────────────────────────────────────────────────┐
│                    llm_client（统一封装层）              │
│  目标：屏蔽调用细节，让上层只面对一个接口                │
└─────────────────────────────────────────────────────────┘
                      │
                      │ 2) 读取配置/初始化客户端
                      │    - model 名称
                      │    - API Key（常来自环境变量）
                      │    - base_url（可选：不同平台）
                      │    - 默认参数（temperature/max_tokens等）
                      ▼
┌─────────────────────────────────────────────────────────┐
│                  构造请求（标准化入参）                   │
│  - model=self.model                                     │
│  - messages=messages                                    │
│  - temperature=temperature                              │
│  - stream=True / False    # 设置流式                     │
└─────────────────────────────────────────────────────────┘
                      │
                      │ 3) 调用模型 SDK / HTTP
                      ▼
┌─────────────────────────────────────────────────────────┐
│                 LLM Provider（OpenAI/其它）              │
│           chat.completions.create(...) 返回响应          │
└─────────────────────────────────────────────────────────┘
                      │
          ┌───────────┴────────────────┐
          │                            │
          │ 4A) 非流式（一次性返回）    │ 4B) 流式（逐块返回）
          │                            │
          ▼                            ▼
┌───────────────────────┐     ┌───────────────────────────┐
│ response.message...    │     │ response 是 iterator       │
│ content = 完整文本     │     │ for chunk in response:     │
└───────────────────────┘     │   delta.content（增量token）│
          │                    │   print（可选）             │
          │                    │   append 到 collected       │
          │                    └───────────────────────────┘
          │                            │
          └──────────────┬─────────────┘
                         │
                         │ 5) 错误处理/重试（可选）
                         │    - 超时、网络错误
                         │    - 解析异常
                         ▼
┌─────────────────────────────────────────────────────────┐
│                 返回给上层：最终字符串 text              │
└─────────────────────────────────────────────────────────┘

```

### llm_client产品能力
- 统一入口
- 配置与密钥管理
- 参数治理（可控性）
- 流式输出
- 错误处理
- 可替换性

### 使用Vibe Coding的PROMPT
`llm_client `作为一个“基础组件”写清楚：
输入：messages + 参数（temperature/stream）
输出：text（字符串）+ 可选 token 事件（用于实时展示）
非功能：可替换模型、错误不崩、日志可查
- 支持模型切换
- 自动重试
- 失败回退（fallback）
- 统计token用量（成本）

## 经典范式-ReAct

> ReAct之前，主流模式是采用CoT（Chain of Thought）和ToT（Tree of Thoughts）引导模型进行推理，但这些方法是进行单论对话推理，且无法与外部更多信息连接，从而容易出现幻觉。

### ReAct原理
Thought → Action → Observation

解决了三个经典问题：
- 不知道自己不知道
- 不会使用外部工具
- 出错不会修正

```text
┌──────────────┐
│   用户问题    │
└──────┬───────┘
       │
       ▼
┌─────────────────────────┐
│   Thought（模型思考）    │
│  · 分析问题              │
│  · 判断是否需要工具      │
└──────┬──────────────────┘
       │
       ▼
┌─────────────────────────┐
│   Action（模型决策）     │
│  · Search[...]           │
│  · Calculator[...]       │
│  · Finish[...]           │
└──────┬──────────────────┘
       │
       ▼
┌─────────────────────────┐
│ Observation（真实世界） │
│ · 工具执行结果           │
│ · 错误 / 数据 / 文本     │
└──────┬──────────────────┘
       │
       ▼
┌─────────────────────────┐
│   写入 History           │
│   作为下一轮上下文       │
└──────┬──────────────────┘
       │
       ├── 未完成 → 回到 Thought
       │
       └── 完成 → Finish[最终答案]

```

### 应用场景
- 需要外部知识任务
- 需要精确计算的任务
- 需要与API交互的任务

### 定义工具`tools`(方法)
一个工具核心要素：
- name：让Agent在`Action`中识别调用
- Description：描述工具能做什么，输入什么，输出什么
- Parameters：工具的参数，包括参数名、类型、是否必填、描述等
- Execution Logic：工具的执行逻辑、方法或函数
定义时，需确定调用的工具传入与传出内容，通常采用papams为传入，client为执行工具，results为输出结果

### 构建工具执行器`ToolExecutor`（类）
核心完成三个事项：
- registerTool(name, description, func)：注册工具
- getTool(name)：按名字拿到可执行函数
- getAvailableTools()：把所有工具的描述拼成字符串，塞进 prompt 里